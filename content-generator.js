#!/usr/bin/env node

/**
 * Content Generator for Twitter Curator
 * ä½¿ç”¨ Gemini AI ç”Ÿæˆç¬¦åˆ Persona çš„æ¨æ–‡å’Œå›è¦†
 */

require('dotenv').config();

const { execSync } = require('child_process');
const fs = require('fs');

/**
 * å¾ Persona æå–é—œéµä¿¡æ¯
 */
function extractPersonaSummary(personaContent) {
  const lines = personaContent.split('\n');
  const keySection = [];

  let capturing = false;
  for (const line of lines) {
    if (line.includes('æ ¸å¿ƒå®šä½') ||
        line.includes('è·æ¥­è§’è‰²') ||
        line.includes('## ğŸ§  æ€ç¶­æ¨¡å¼') ||
        line.includes('## ğŸ’¡ æ ¸å¿ƒåƒ¹å€¼è§€') ||
        line.includes('## ğŸ¯ ç•¶å‰ç„¦é»')) {
      capturing = true;
    }
    if ((line.includes('## ğŸ“Š å·¥ä½œæ¨¡å¼') ||
         line.includes('## ğŸ› ï¸ å¸¸ç”¨å·¥å…·') ||
         line.includes('## ğŸ“ˆ DayFlow Intelligence')) && keySection.length > 0) {
      break;
    }
    if (capturing) {
      keySection.push(line);
    }
  }

  return keySection.join('\n').substring(0, 2000);
}

/**
 * ä½¿ç”¨ Ollama ç”ŸæˆåŸå‰µæ¨æ–‡
 */
async function generateOriginalTweet(persona, topic, apiKey) {
  const personaSummary = extractPersonaSummary(persona);

  // å¾ Medium å¯«ä½œé¢¨æ ¼åˆ†æä¸­æå–çš„æ¨æ–‡ hooks
  const hooks = [
    'Have you ever wondered...',
    'Everyone says X, but actually...',
    'From what I\'ve observed over the years...',
    'What we\'ll see next is...',
    'The real question is...',
    'Here\'s what most people miss...'
  ];
  const randomHook = hooks[Math.floor(Math.random() * hooks.length)];

  // å¾ 204 ç¯‡æ–‡ç« åˆ†æå¾—å‡ºçš„å¯«ä½œé¢¨æ ¼æŒ‡å°
  const styleGuide = `
Lman's Voice (based on 204 Medium articles, 2015-2025):
- Direct, no-nonsense communication
- Focus on practical insights over theory
- Critical thinking, challenge mainstream views
- Share first-hand experience from startup journey
- Connect technology with business value
- Pragmatic + idealistic mindset

Example phrases:
- "Blockchain solves trust problems, not technical problems"
- "Innovation's biggest enemy isn't failure, it's organizational inertia"
- "AI landing isn't about computing power, it's about scenario understanding"
`;

  const prompt = `Write a tweet as Lman (Tech Entrepreneur, Blockchain & AI Thought Leader, IrisGo.AI CoFounder).

${styleGuide}

Topic: ${topic}
Hook template: ${randomHook}

Requirements:
- Max 280 characters
- English only
- NO hashtags, minimal emojis
- Direct and authentic tone
- Business insight + technical depth
- Challenge common assumptions when relevant
- Share actionable perspective

Output ONLY the tweet text, nothing else:`;

  try {
    const response = await callGeminiAPI(prompt, apiKey);
    return cleanContent(response);
  } catch (error) {
    console.error('Error generating tweet:', error.message);
    return null;
  }
}

/**
 * ä½¿ç”¨ Ollama ç”Ÿæˆæ¨æ–‡å›è¦†
 */
async function generateReply(tweetText, tweetAuthor, persona, apiKey) {
  const prompt = `Reply to this tweet as Lman (startup builder, AI/tech expert):

@${tweetAuthor}: "${tweetText}"

Requirements:
- Max 280 characters
- English only
- No hashtags
- Conversational, add value
- Technical but friendly

Output ONLY the reply text:`;

  try {
    const response = await callGeminiAPI(prompt, apiKey);
    return cleanContent(response);
  } catch (error) {
    console.error('Error generating reply:', error.message);
    return null;
  }
}

/**
 * èª¿ç”¨æœ¬åœ° Ollama API (gpt-oss:20b with fallback)
 */
async function callGeminiAPI(prompt, apiKey) {
  const url = 'http://localhost:11434/api/generate';

  // æ¨¡å‹åˆ—è¡¨ï¼šå„ªå…ˆä½¿ç”¨ gpt-oss:20bï¼Œå¤±æ•—æ™‚ fallback åˆ° qwen3:32b
  const models = ['gpt-oss:20b', 'qwen3:32b'];

  for (const model of models) {
    try {
      const payload = {
        model: model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.7,
          num_predict: 200,
          top_p: 0.9,
        }
      };

      const command = `curl -s -X POST '${url}' \
        -H 'Content-Type: application/json' \
        -d '${JSON.stringify(payload).replace(/'/g, "'\\''")}'`;

      const response = execSync(command, { encoding: 'utf-8', timeout: 60000 });
      const data = JSON.parse(response);

      // gpt-oss model puts content in 'thinking' field
      if (data.thinking) {
        console.log(`[INFO] Using model: ${model}`);
        return data.thinking;
      } else if (data.response) {
        console.log(`[INFO] Using model: ${model}`);
        return data.response;
      }

      // å¦‚æœæ²’æœ‰æœ‰æ•ˆéŸ¿æ‡‰ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
      throw new Error('No valid response from model');

    } catch (error) {
      console.log(`[WARN] Model ${model} failed: ${error.message}, trying next...`);
      // ç¹¼çºŒå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
      continue;
    }
  }

  throw new Error('All Ollama models failed');
}

/**
 * æ¸…ç†ç”Ÿæˆçš„å…§å®¹ (å¾ Ollama thinking ä¸­æå–å¯¦éš›æ¨æ–‡)
 */
function cleanContent(content) {
  console.log(`[DEBUG] Cleaning content, length: ${content.length}`);

  // å˜—è©¦æå–æ‰€æœ‰å¼•è™Ÿä¸­çš„å…§å®¹
  const allQuotes = content.match(/"([^"]+)"/g);

  if (allQuotes && allQuotes.length > 0) {
    // éæ¿¾æ‰åŒ…å« prompt é—œéµå­—çš„å¼•è™Ÿ
    const promptKeywords = ['Topic:', 'Requirements:', 'Output ONLY', 'Max 280', 'Style:', 'Write a tweet', 'CoFounder at'];

    const validQuotes = allQuotes
      .map(q => q.replace(/"/g, '').trim())
      .filter(q => {
        // æ’é™¤å¤ªçŸ­çš„ï¼ˆ<20 å­—ç¬¦ï¼‰
        if (q.length < 20) return false;
        // æ’é™¤åŒ…å« prompt é—œéµå­—çš„
        if (promptKeywords.some(kw => q.includes(kw))) return false;
        return true;
      });

    if (validQuotes.length > 0) {
      // é¸æ“‡æœ€é•·çš„æœ‰æ•ˆå…§å®¹
      const longest = validQuotes.reduce((a, b) => a.length > b.length ? a : b);
      const cleaned = longest
        .replace(/\n+/g, ' ')
        .replace(/\s+/g, ' ')
        .trim()
        .substring(0, 280);

      console.log(`[INFO] Extracted tweet: ${cleaned.substring(0, 100)}...`);
      return cleaned;
    }
  }

  // Fallback: ç›´æ¥æ¸…ç†åŸå§‹å…§å®¹
  console.log('[WARN] No quoted content found, using fallback cleaning');
  const cleaned = content
    .replace(/^["']|["']$/g, '')
    .replace(/\n+/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
    .substring(0, 280);

  // å¦‚æœ fallback å…§å®¹åŒ…å«å¤ªå¤š prompt é—œéµå­—ï¼Œè¿”å› null
  const promptKeywords = ['Topic:', 'Requirements:', 'Output ONLY', 'Max 280'];
  const keywordCount = promptKeywords.filter(kw => cleaned.includes(kw)).length;

  if (keywordCount >= 2) {
    console.log('[ERROR] Could not extract clean tweet from model output');
    return null;
  }

  return cleaned;
}

/**
 * éš¨æ©Ÿé¸æ“‡ä¸»é¡Œ
 */
function selectRandomTopic(topics) {
  return topics[Math.floor(Math.random() * topics.length)];
}

module.exports = {
  generateOriginalTweet,
  generateReply,
  selectRandomTopic,
  extractPersonaSummary
};

// CLI æ¸¬è©¦
if (require.main === module) {
  const config = require('./config');
  const persona = fs.readFileSync(config.PERSONA_FILE, 'utf-8');
  const topic = selectRandomTopic(config.TOPICS);

  console.log('ğŸ§ª Testing content generation...\n');
  console.log(`Selected topic: ${topic}\n`);

  generateOriginalTweet(persona, topic, config.GEMINI_API_KEY).then(tweet => {
    console.log('âœ… Generated tweet:');
    console.log(`"${tweet}"\n`);
    console.log(`Length: ${tweet.length} characters`);
  }).catch(error => {
    console.error('âŒ Error:', error);
    process.exit(1);
  });
}
